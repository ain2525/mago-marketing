import streamlit as st
import pandas as pd
import altair as alt
from datetime import datetime, timedelta

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ã¾ã”ã“ã‚ã‚µãƒãƒ¼ãƒˆåˆ†æ v8", layout="wide")
st.title("ğŸ“Š ã¾ã”ã“ã‚ã‚µãƒãƒ¼ãƒˆï¼šåºƒå‘ŠÃ—å•†è«‡ åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•° ---
def load_data(file):
    try:
        if file.name.endswith('.csv'):
            try:
                return pd.read_csv(file)
            except:
                return pd.read_csv(file, encoding='shift-jis')
        else:
            return pd.read_excel(file)
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("âš™ï¸ åˆ¤å®šåŸºæº–ã®è¨­å®š")
cpa_limit = st.sidebar.number_input("è¨±å®¹CPAï¼ˆå††ï¼‰", value=10000, step=1000)
connect_target = st.sidebar.slider("ç›®æ¨™æ¥ç¶šç‡ï¼ˆ%ï¼‰", 0, 100, 50)
meeting_target = st.sidebar.slider("ç›®æ¨™å•†è«‡åŒ–ç‡ï¼ˆ%ï¼‰", 0, 50, 18)

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
col1, col2 = st.columns(2)
with col1:
    meta_file = st.file_uploader("ğŸ“‚ Metaåºƒå‘Šå®Ÿç¸¾", type=['xlsx', 'csv'])
with col2:
    hs_file = st.file_uploader("ğŸ“‚ HubSpotãƒ‡ãƒ¼ã‚¿", type=['xlsx', 'csv'])

st.divider()

# --- åˆ†æå®Ÿè¡Œ ---
if meta_file and hs_file:
    df_meta = load_data(meta_file)
    df_hs = load_data(hs_file)

    if df_meta is not None and df_hs is not None:
        try:
            # === Metaå´ï¼šåˆ—ã®ç‰¹å®š ===
            meta_cols = list(df_meta.columns)
            name_col = next((c for c in meta_cols if 'åå‰' in str(c) or 'Name' in str(c)), None)
            spend_col = next((c for c in meta_cols if 'æ¶ˆåŒ–é‡‘é¡' in str(c) or 'Amount' in str(c) or 'è²»ç”¨' in str(c)), None)
            date_col_meta = next((c for c in meta_cols if 'æ—¥' in str(c) or 'Date' in str(c) or 'é–‹å§‹' in str(c)), None)

            # === HubSpotå´ï¼šåˆ—ã®ç‰¹å®š ===
            hs_cols = list(df_hs.columns)
            utm_col = next((c for c in hs_cols if 'UTM' in str(c) or 'Content' in str(c)), None)
            connect_col = next((c for c in hs_cols if 'æ¥ç¶š' in str(c)), None)
            deal_col = next((c for c in hs_cols if 'å•†è«‡' in str(c)), None)
            date_col_hs = next((c for c in hs_cols if 'ä½œæˆæ—¥' in str(c) or 'Created' in str(c) or 'æ—¥ä»˜' in str(c)), None)

            if not all([name_col, spend_col, utm_col]):
                st.error(f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\nMeta: åºƒå‘Šå={name_col}, æ¶ˆåŒ–é‡‘é¡={spend_col}\nHubSpot: UTM={utm_col}")
                st.stop()

            # === æ—¥ä»˜åˆ—ã®å¤‰æ› ===
            if date_col_meta:
                df_meta[date_col_meta] = pd.to_datetime(df_meta[date_col_meta], errors='coerce')
            if date_col_hs:
                df_hs[date_col_hs] = pd.to_datetime(df_hs[date_col_hs], errors='coerce')

            # === æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ===
            st.subheader("ğŸ“… åˆ†ææœŸé–“ã®è¨­å®š")
            filter_enabled = st.checkbox("æœŸé–“ã§çµã‚Šè¾¼ã‚€", value=False)
            
            if filter_enabled:
                col_date1, col_date2 = st.columns(2)
                with col_date1:
                    if date_col_hs:
                        min_date_hs = df_hs[date_col_hs].min()
                        start_date = st.date_input("é–‹å§‹æ—¥", value=min_date_hs if pd.notna(min_date_hs) else datetime.now() - timedelta(days=30))
                    else:
                        start_date = st.date_input("é–‹å§‹æ—¥", value=datetime.now() - timedelta(days=30))
                with col_date2:
                    if date_col_hs:
                        max_date_hs = df_hs[date_col_hs].max()
                        end_date = st.date_input("çµ‚äº†æ—¥", value=max_date_hs if pd.notna(max_date_hs) else datetime.now())
                    else:
                        end_date = st.date_input("çµ‚äº†æ—¥", value=datetime.now())
                
                start_datetime = pd.to_datetime(start_date)
                end_datetime = pd.to_datetime(end_date) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
                
                if date_col_meta:
                    df_meta = df_meta[(df_meta[date_col_meta] >= start_datetime) & (df_meta[date_col_meta] <= end_datetime)]
                if date_col_hs:
                    df_hs = df_hs[(df_hs[date_col_hs] >= start_datetime) & (df_hs[date_col_hs] <= end_datetime)]
                
                st.info(f"ğŸ“Š åˆ†ææœŸé–“: {start_date} ã€œ {end_date}")

            st.divider()

            # === ãƒ‡ãƒãƒƒã‚°æƒ…å ± ===
            st.sidebar.markdown("---")
            st.sidebar.subheader("ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±")
            st.sidebar.write(f"**Metaåºƒå‘Šãƒ‡ãƒ¼ã‚¿:** {len(df_meta)}è¡Œ")
            st.sidebar.write(f"**HubSpotãƒ‡ãƒ¼ã‚¿:** {len(df_hs)}è¡Œ")
            
            if deal_col:
                st.sidebar.write(f"**å•†è«‡åˆ—å:** `{deal_col}`")
                deal_values = df_hs[deal_col].fillna('(ç©ºç™½)').astype(str).value_counts()
                st.sidebar.write("**å•†è«‡åˆ—ã®å€¤:**")
                st.sidebar.dataframe(deal_values, use_container_width=True)

            # === 1. ãƒ‡ãƒ¼ã‚¿çµåˆã‚­ãƒ¼ã®ä½œæˆ ===
            df_meta['key'] = df_meta[name_col].astype(str).str.extract(r'(bn\d+)', expand=False)
            df_hs['key'] = df_hs[utm_col].astype(str).str.strip()
            
            df_meta = df_meta[df_meta['key'].notna()]
            df_hs = df_hs[df_hs['key'].notna()]

            # === 2. Metaå´ã®æ¶ˆåŒ–é‡‘é¡é›†è¨ˆ ===
            meta_spend = df_meta.groupby('key')[spend_col].sum().reset_index()
            meta_spend[spend_col] = pd.to_numeric(meta_spend[spend_col], errors='coerce').fillna(0)
            
            st.sidebar.markdown("---")
            st.sidebar.write("**Metaæ¶ˆåŒ–é‡‘é¡ï¼ˆãƒãƒŠãƒ¼åˆ¥ï¼‰:**")
            st.sidebar.dataframe(meta_spend.rename(columns={'key': 'ãƒãƒŠãƒ¼', spend_col: 'æ¶ˆåŒ–é‡‘é¡'}), use_container_width=True)

            # === 3. HubSpotå´ã§ãƒªãƒ¼ãƒ‰æ•°ãƒ»æ¥ç¶šãƒ»å•†è«‡ã‚’ã‚«ã‚¦ãƒ³ãƒˆ ===
            hs_summary = df_hs.groupby('key').agg(
                ãƒªãƒ¼ãƒ‰æ•°=('key', 'size')
            ).reset_index()

            # æ¥ç¶šæ•°
            if connect_col:
                connect_df = df_hs[df_hs[connect_col].fillna('').astype(str).str.contains('ã‚ã‚Š|TRUE|Yes|true|æ¸ˆ', case=False, na=False)]
                connect_count = connect_df.groupby('key').size().reset_index(name='æ¥ç¶šæ•°')
                hs_summary = pd.merge(hs_summary, connect_count, on='key', how='left')
            else:
                hs_summary['æ¥ç¶šæ•°'] = 0
            
            # å•†è«‡å®Ÿæ–½æ•°ãƒ»äºˆç´„æ•°
            if deal_col:
                df_hs['å•†è«‡_normalized'] = df_hs[deal_col].fillna('').astype(str).str.lower().str.strip()
                
                deal_done = df_hs[
                    (df_hs['å•†è«‡_normalized'].str.contains('ã‚ã‚Š|æ¸ˆ|å®Œäº†|å®Ÿæ–½|done|yes|true', case=False, na=False)) &
                    (~df_hs['å•†è«‡_normalized'].str.contains('äºˆç´„|äºˆå®š|scheduled', case=False, na=False))
                ]
                deal_done_count = deal_done.groupby('key').size().reset_index(name='å•†è«‡å®Ÿæ–½æ•°')
                
                deal_plan = df_hs[df_hs['å•†è«‡_normalized'].str.contains('äºˆç´„|äºˆå®š|scheduled', case=False, na=False)]
                deal_plan_count = deal_plan.groupby('key').size().reset_index(name='å•†è«‡äºˆç´„æ•°')
                
                st.sidebar.write(f"âœ… å•†è«‡å®Ÿæ–½: **{len(deal_done)}ä»¶**")
                st.sidebar.write(f"ğŸ“… å•†è«‡äºˆç´„: **{len(deal_plan)}ä»¶**")
                
                hs_summary = pd.merge(hs_summary, deal_done_count, on='key', how='left')
                hs_summary = pd.merge(hs_summary, deal_plan_count, on='key', how='left')
            else:
                hs_summary['å•†è«‡å®Ÿæ–½æ•°'] = 0
                hs_summary['å•†è«‡äºˆç´„æ•°'] = 0

            hs_summary = hs_summary.fillna(0)
            hs_summary['æ¥ç¶šæ•°'] = hs_summary['æ¥ç¶šæ•°'].astype(int)
            hs_summary['å•†è«‡å®Ÿæ–½æ•°'] = hs_summary['å•†è«‡å®Ÿæ–½æ•°'].astype(int)
            hs_summary['å•†è«‡äºˆç´„æ•°'] = hs_summary['å•†è«‡äºˆç´„æ•°'].astype(int)

            # === 4. Metaæ¶ˆåŒ–é‡‘é¡ã¨çµåˆ ===
            result = pd.merge(hs_summary, meta_spend, on='key', how='left')
            result[spend_col] = result[spend_col].fillna(0)

            # === 5. æŒ‡æ¨™è¨ˆç®— ===
            result['CPA'] = result.apply(
                lambda x: int(x[spend_col] / x['ãƒªãƒ¼ãƒ‰æ•°']) if x['ãƒªãƒ¼ãƒ‰æ•°'] > 0 else 0,
                axis=1
            )
            result['æ¥ç¶šç‡'] = result.apply(
                lambda x: (x['æ¥ç¶šæ•°'] / x['ãƒªãƒ¼ãƒ‰æ•°'] * 100) if x['ãƒªãƒ¼ãƒ‰æ•°'] > 0 else 0,
                axis=1
            )
            result['å•†è«‡åŒ–ç‡'] = result.apply(
                lambda x: ((x['å•†è«‡å®Ÿæ–½æ•°'] + x['å•†è«‡äºˆç´„æ•°']) / x['ãƒªãƒ¼ãƒ‰æ•°'] * 100) if x['ãƒªãƒ¼ãƒ‰æ•°'] > 0 else 0,
                axis=1
            )

            # === 6. åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå•†è«‡åŒ–ç‡é‡è¦–ç‰ˆï¼‰ ===
            def judge(row):
                cpa_ok = row['CPA'] > 0 and row['CPA'] <= cpa_limit
                connect_ok = row['æ¥ç¶šç‡'] >= connect_target
                meeting_ok = row['å•†è«‡åŒ–ç‡'] >= meeting_target
                
                conditions_met = sum([cpa_ok, connect_ok, meeting_ok])
                
                # å•†è«‡åŒ–ç‡ãŒç›®æ¨™ä»¥ä¸Šãªã‚‰æœ€å„ªç§€ã®å¯èƒ½æ€§ã‚ã‚Š
                if conditions_met == 3:
                    return "ğŸ† æœ€å„ªç§€"
                elif conditions_met == 2 and meeting_ok:
                    return "ğŸ¥‡ å„ªç§€"
                elif conditions_met == 2:
                    return "ğŸŸ¡ è¦æ”¹å–„"
                elif conditions_met == 1 and meeting_ok:
                    return "ğŸŸ¡ è¦æ”¹å–„"
                else:
                    return "ğŸ›‘ åœæ­¢æ¨å¥¨"
            
            result['åˆ¤å®š'] = result.apply(judge, axis=1)

            # === 7. å…¨ä½“ã‚µãƒãƒªãƒ¼ ===
            total_spend = result[spend_col].sum()
            total_leads = result['ãƒªãƒ¼ãƒ‰æ•°'].sum()
            total_connect = result['æ¥ç¶šæ•°'].sum()
            total_deal = result['å•†è«‡å®Ÿæ–½æ•°'].sum()
            total_plan = result['å•†è«‡äºˆç´„æ•°'].sum()
            avg_cpa = int(total_spend / total_leads) if total_leads > 0 else 0
            avg_connect = (total_connect / total_leads * 100) if total_leads > 0 else 0
            avg_meeting = ((total_deal + total_plan) / total_leads * 100) if total_leads > 0 else 0

            st.subheader("ğŸ“ˆ å…¨ä½“å®Ÿç¸¾ã‚µãƒãƒªãƒ¼")
            k1, k2, k3 = st.columns(3)
            k1.metric("ç·æ¶ˆåŒ–é‡‘é¡", f"Â¥{int(total_spend):,}")
            k1.metric("ç·ãƒªãƒ¼ãƒ‰æ•°", f"{int(total_leads)}ä»¶")
            
            k2.metric("æ¥ç¶šæ•°", f"{int(total_connect)}ä»¶", delta=f"{avg_connect:.1f}%")
            k2.metric("å¹³å‡CPA", f"Â¥{avg_cpa:,}")
            
            k3.metric("å•†è«‡å®Ÿæ–½æ•°", f"{int(total_deal)}ä»¶")
            k3.metric("å•†è«‡äºˆç´„æ•°", f"{int(total_plan)}ä»¶", delta=f"åŒ–ç‡{avg_meeting:.1f}%")

            st.divider()

            # === 8. ãƒãƒŠãƒ¼åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ===
            st.subheader("ğŸ“Š ãƒãƒŠãƒ¼åˆ¥ ç·åˆè©•ä¾¡")
            
            chart_data = result[result['ãƒªãƒ¼ãƒ‰æ•°'] > 0].copy()
            if len(chart_data) > 0:
                chart = alt.Chart(chart_data).mark_circle(size=200).encode(
                    x=alt.X('CPA:Q', title='CPA (å††)', scale=alt.Scale(zero=False)),
                    y=alt.Y('å•†è«‡åŒ–ç‡:Q', title='å•†è«‡åŒ–ç‡ (%)'),
                    color=alt.Color('åˆ¤å®š:N', legend=alt.Legend(title="åˆ¤å®š")),
                    size=alt.Size('ãƒªãƒ¼ãƒ‰æ•°:Q', legend=None),
                    tooltip=['key', 'CPA', 'æ¥ç¶šç‡', 'å•†è«‡åŒ–ç‡', 'ãƒªãƒ¼ãƒ‰æ•°', 'åˆ¤å®š']
                ).properties(height=400).interactive()
                st.altair_chart(chart, use_container_width=True)

            st.markdown("---")

            # === 9. ãƒãƒŠãƒ¼åˆ¥è©•ä¾¡è¡¨ï¼ˆæ•°å€¤è¡¨è¨˜æ”¹å–„ç‰ˆï¼‰ ===
            st.subheader("ğŸ“‹ ãƒãƒŠãƒ¼åˆ¥ è©•ä¾¡è¡¨")
            
            display_df = result.copy()
            display_df = display_df.rename(columns={
                'key': 'ãƒãƒŠãƒ¼ID',
                spend_col: 'æ¶ˆåŒ–é‡‘é¡'
            })
            
            # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç”¨ã®ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
            display_df['æ¶ˆåŒ–é‡‘é¡_è¡¨ç¤º'] = display_df['æ¶ˆåŒ–é‡‘é¡'].apply(lambda x: f"{int(x):,}")
            display_df['CPA_è¡¨ç¤º'] = display_df['CPA'].apply(lambda x: f"{int(x):,}")
            display_df['æ¥ç¶šç‡_è¡¨ç¤º'] = display_df['æ¥ç¶šç‡'].apply(lambda x: f"{x:.1f}%")
            display_df['å•†è«‡åŒ–ç‡_è¡¨ç¤º'] = display_df['å•†è«‡åŒ–ç‡'].apply(lambda x: f"{x:.1f}%")
            
            # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            show_df = display_df[['åˆ¤å®š', 'ãƒãƒŠãƒ¼ID', 'æ¶ˆåŒ–é‡‘é¡_è¡¨ç¤º', 'ãƒªãƒ¼ãƒ‰æ•°', 'CPA_è¡¨ç¤º', 'æ¥ç¶šç‡_è¡¨ç¤º', 'å•†è«‡åŒ–ç‡_è¡¨ç¤º', 'å•†è«‡å®Ÿæ–½æ•°', 'å•†è«‡äºˆç´„æ•°']].copy()
            show_df.columns = ['åˆ¤å®š', 'ãƒãƒŠãƒ¼ID', 'æ¶ˆåŒ–é‡‘é¡', 'ãƒªãƒ¼ãƒ‰æ•°', 'CPA', 'æ¥ç¶šç‡', 'å•†è«‡åŒ–ç‡', 'å•†è«‡å®Ÿæ–½æ•°', 'å•†è«‡äºˆç´„æ•°']
            show_df = show_df.sort_values(by='å•†è«‡åŒ–ç‡', ascending=False, key=lambda x: display_df['å•†è«‡åŒ–ç‡'])
            
            # è‰²ä»˜ã‘ç”¨ã«å…ƒã®åˆ¤å®šåˆ—ã‚’ä¿æŒ
            def highlight_row(row):
                åˆ¤å®š = row['åˆ¤å®š']
                if åˆ¤å®š == "ğŸ† æœ€å„ªç§€":
                    color = 'background-color: #d4edda'
                elif "å„ªç§€" in åˆ¤å®š:
                    color = 'background-color: #d1ecf1'
                elif "è¦æ”¹å–„" in åˆ¤å®š:
                    color = 'background-color: #fff3cd'
                elif "åœæ­¢" in åˆ¤å®š:
                    color = 'background-color: #f8d7da'
                else:
                    color = ''
                return [color] * len(row)
            
            st.dataframe(
                show_df.style.apply(highlight_row, axis=1),
                use_container_width=True,
                hide_index=True
            )

            # === 10. AIã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ ===
            st.divider()
            st.subheader("ğŸ¤– AIã«ã‚ˆã‚‹è©•ä¾¡ã¨æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
            
            best = result[result['åˆ¤å®š'] == "ğŸ† æœ€å„ªç§€"]['key'].tolist()
            good = result[result['åˆ¤å®š'].str.contains("å„ªç§€", na=False)]['key'].tolist()
            improve = result[result['åˆ¤å®š'].str.contains("è¦æ”¹å–„", na=False)]['key'].tolist()
            stop = result[result['åˆ¤å®š'] == "ğŸ›‘ åœæ­¢æ¨å¥¨"]['key'].tolist()
            
            if best:
                st.success(f"**ã€äºˆç®—é›†ä¸­ï¼ã€‘** {', '.join(best)} â†’ CPAãƒ»æ¥ç¶šç‡ãƒ»å•†è«‡åŒ–ç‡ã™ã¹ã¦åŸºæº–ã‚¯ãƒªã‚¢ã€‚äºˆç®—ã‚’æœ€å¤§åŒ–ã—ã¦ãã ã•ã„ã€‚")
            if good:
                good_filtered = [b for b in good if b not in best]
                if good_filtered:
                    st.info(f"**ã€æœ‰æœ›æ ªã€‘** {', '.join(good_filtered)} â†’ å•†è«‡åŒ–ç‡ã¯ç›®æ¨™é”æˆã€‚CPA or æ¥ç¶šç‡ã‚’æ”¹å–„ã™ã‚Œã°æœ€å„ªç§€ã«ã€‚")
            if improve:
                st.warning(f"**ã€è¦åˆ†æã€‘** {', '.join(improve)} â†’ LPæ”¹å–„ã‚„æ¥ç¶šä½“åˆ¶ã®è¦‹ç›´ã—ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
            if stop:
                st.error(f"**ã€åœæ­¢æ¤œè¨ã€‘** {', '.join(stop)} â†’ äºˆç®—ã‚’å„ªç§€ãƒãƒŠãƒ¼ã«æŒ¯ã‚Šæ›¿ãˆã¦ãã ã•ã„ã€‚")

        except Exception as e:
            st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            st.code(traceback.format_exc())

else:
    st.info("ğŸ‘† 2ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨åˆ†æãŒå§‹ã¾ã‚Šã¾ã™")
